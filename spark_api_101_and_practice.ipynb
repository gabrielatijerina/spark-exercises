{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Spark API Roadmap / Cheatsheet](https://zgul.de/teaching/spark-api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pyspark library\n",
    "import pyspark\n",
    "\n",
    "#creating spark object (necessary to creating spark dfs)\n",
    "spark = pyspark.sql.SparkSession.builder.getOrCreate() #once per notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.0.7:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fbadf14a400>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fancy nice html representation\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pydataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrame Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[total_bill: double, tip: double, sex: string, smoker: string, day: string, time: string, size: bigint]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading tips dataset from pydataset\n",
    "tips = pydataset.data('tips')\n",
    "\n",
    "#spark doesn't load any data until it has to\n",
    "df = spark.createDataFrame(tips)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|\n",
      "+----------+----+------+------+---+------+----+\n",
      "|     16.99|1.01|Female|    No|Sun|Dinner|   2|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|\n",
      "|     21.01| 3.5|  Male|    No|Sun|Dinner|   3|\n",
      "|     23.68|3.31|  Male|    No|Sun|Dinner|   2|\n",
      "|     24.59|3.61|Female|    No|Sun|Dinner|   4|\n",
      "|     25.29|4.71|  Male|    No|Sun|Dinner|   4|\n",
      "|      8.77| 2.0|  Male|    No|Sun|Dinner|   2|\n",
      "|     26.88|3.12|  Male|    No|Sun|Dinner|   4|\n",
      "|     15.04|1.96|  Male|    No|Sun|Dinner|   2|\n",
      "|     14.78|3.23|  Male|    No|Sun|Dinner|   2|\n",
      "|     10.27|1.71|  Male|    No|Sun|Dinner|   2|\n",
      "|     35.26| 5.0|Female|    No|Sun|Dinner|   4|\n",
      "|     15.42|1.57|  Male|    No|Sun|Dinner|   2|\n",
      "|     18.43| 3.0|  Male|    No|Sun|Dinner|   4|\n",
      "|     14.83|3.02|Female|    No|Sun|Dinner|   2|\n",
      "|     21.58|3.92|  Male|    No|Sun|Dinner|   2|\n",
      "|     10.33|1.67|Female|    No|Sun|Dinner|   3|\n",
      "|     16.29|3.71|  Male|    No|Sun|Dinner|   3|\n",
      "|     16.97| 3.5|Female|    No|Sun|Dinner|   3|\n",
      "|     20.65|3.35|  Male|    No|Sat|Dinner|   3|\n",
      "+----------+----+------+------+---+------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#load data w/ .show()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|\n",
      "+----------+----+------+------+---+------+----+\n",
      "|     16.99|1.01|Female|    No|Sun|Dinner|   2|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|\n",
      "|     21.01| 3.5|  Male|    No|Sun|Dinner|   3|\n",
      "|     23.68|3.31|  Male|    No|Sun|Dinner|   2|\n",
      "|     24.59|3.61|Female|    No|Sun|Dinner|   4|\n",
      "|     25.29|4.71|  Male|    No|Sun|Dinner|   4|\n",
      "|      8.77| 2.0|  Male|    No|Sun|Dinner|   2|\n",
      "|     26.88|3.12|  Male|    No|Sun|Dinner|   4|\n",
      "|     15.04|1.96|  Male|    No|Sun|Dinner|   2|\n",
      "|     14.78|3.23|  Male|    No|Sun|Dinner|   2|\n",
      "+----------+----+------+------+---+------+----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#pass a number in\n",
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|\n",
      "+----------+----+------+------+---+------+----+\n",
      "|     16.99|1.01|Female|    No|Sun|Dinner|   2|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|\n",
      "|     21.01| 3.5|  Male|    No|Sun|Dinner|   3|\n",
      "|     23.68|3.31|  Male|    No|Sun|Dinner|   2|\n",
      "|     24.59|3.61|Female|    No|Sun|Dinner|   4|\n",
      "|     25.29|4.71|  Male|    No|Sun|Dinner|   4|\n",
      "|      8.77| 2.0|  Male|    No|Sun|Dinner|   2|\n",
      "|     26.88|3.12|  Male|    No|Sun|Dinner|   4|\n",
      "|     15.04|1.96|  Male|    No|Sun|Dinner|   2|\n",
      "|     14.78|3.23|  Male|    No|Sun|Dinner|   2|\n",
      "+----------+----+------+------+---+------+----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#common mistake\n",
    "df2 = df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reassigning gives back nothing\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NoneType"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#.show() is like a print statement, it doesn't return anything\n",
    "# Don't reassign to a variable\n",
    "#.show() is just to view contents\n",
    "type(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(total_bill=16.99, tip=1.01, sex='Female', smoker='No', day='Sun', time='Dinner', size=2),\n",
       " Row(total_bill=10.34, tip=1.66, sex='Male', smoker='No', day='Sun', time='Dinner', size=3),\n",
       " Row(total_bill=21.01, tip=3.5, sex='Male', smoker='No', day='Sun', time='Dinner', size=3),\n",
       " Row(total_bill=23.68, tip=3.31, sex='Male', smoker='No', day='Sun', time='Dinner', size=2),\n",
       " Row(total_bill=24.59, tip=3.61, sex='Female', smoker='No', day='Sun', time='Dinner', size=4)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#work with values in the df\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(total_bill=16.99, tip=1.01, sex='Female', smoker='No', day='Sun', time='Dinner', size=2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show row contents\n",
    "df.head(5)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.01"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show value for tip\n",
    "df.head(5)[0].tip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[total_bill: double, tip: double, size: bigint, day: string]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pull specific columns w/ .select and pass col names you want\n",
    "df.select('total_bill', 'tip', 'size', 'day')\n",
    "#specified a transformation, and not an action (that is why we don't see anything b/c you need .show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+----+---+\n",
      "|total_bill| tip|size|day|\n",
      "+----------+----+----+---+\n",
      "|     16.99|1.01|   2|Sun|\n",
      "|     10.34|1.66|   3|Sun|\n",
      "|     21.01| 3.5|   3|Sun|\n",
      "|     23.68|3.31|   2|Sun|\n",
      "|     24.59|3.61|   4|Sun|\n",
      "|     25.29|4.71|   4|Sun|\n",
      "|      8.77| 2.0|   2|Sun|\n",
      "|     26.88|3.12|   4|Sun|\n",
      "|     15.04|1.96|   2|Sun|\n",
      "|     14.78|3.23|   2|Sun|\n",
      "|     10.27|1.71|   2|Sun|\n",
      "|     35.26| 5.0|   4|Sun|\n",
      "|     15.42|1.57|   2|Sun|\n",
      "|     18.43| 3.0|   4|Sun|\n",
      "|     14.83|3.02|   2|Sun|\n",
      "|     21.58|3.92|   2|Sun|\n",
      "|     10.33|1.67|   3|Sun|\n",
      "|     16.29|3.71|   3|Sun|\n",
      "|     16.97| 3.5|   3|Sun|\n",
      "|     20.65|3.35|   3|Sat|\n",
      "+----------+----+----+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#show values\n",
    "df.select('total_bill', 'tip', 'size', 'day').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[total_bill: double, tip: double, sex: string, smoker: string, day: string, time: string, size: bigint]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#like sql, get back every col\n",
    "df.select('*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'tip'>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reference col name (spark col object), but no data\n",
    "df.tip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'(tip / total_bill)'>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tip percentage\n",
    "df.tip / df.total_bill\n",
    "#syntax looks like pandas, but result is different\n",
    "#the column represents the transformation, but isn't full of values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "| (tip / total_bill)|\n",
      "+-------------------+\n",
      "|0.05944673337257211|\n",
      "|0.16054158607350097|\n",
      "|0.16658733936220846|\n",
      "| 0.1397804054054054|\n",
      "|0.14680764538430255|\n",
      "+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#specify w/ .select () and .show() to show results\n",
    "df.select(df.tip / df.total_bill).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'(tip / total_bill)'>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#take expressions and store in a new col\n",
    "col = df.tip / df.total_bill\n",
    "col\n",
    "#holds expression that represents new col, but no data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "| (tip / total_bill)|\n",
      "+-------------------+\n",
      "|0.05944673337257211|\n",
      "|0.16054158607350097|\n",
      "|0.16658733936220846|\n",
      "| 0.1397804054054054|\n",
      "|0.14680764538430255|\n",
      "+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#see what we end up with and make modifications\n",
    "df.select(col).show(5)\n",
    "#by default, name of col, is the operation that was performed\n",
    "#so add alias (transforms column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|            tip_pct|\n",
      "+-------------------+\n",
      "|0.05944673337257211|\n",
      "|0.16054158607350097|\n",
      "|0.16658733936220846|\n",
      "| 0.1397804054054054|\n",
      "|0.14680764538430255|\n",
      "+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#using .alias to rename col\n",
    "df.select(col.alias('tip_pct')).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+-------------------+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|            tip_pct|\n",
      "+----------+----+------+------+---+------+----+-------------------+\n",
      "|     16.99|1.01|Female|    No|Sun|Dinner|   2|0.05944673337257211|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|0.16054158607350097|\n",
      "|     21.01| 3.5|  Male|    No|Sun|Dinner|   3|0.16658733936220846|\n",
      "|     23.68|3.31|  Male|    No|Sun|Dinner|   2| 0.1397804054054054|\n",
      "|     24.59|3.61|Female|    No|Sun|Dinner|   4|0.14680764538430255|\n",
      "+----------+----+------+------+---+------+----+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#add new col to df by doing .select('*', new_col.alias('new_col_name'))\n",
    "df.select(\"*\", col.alias('tip_pct')).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|\n",
      "+----------+----+------+------+---+------+----+\n",
      "|     16.99|1.01|Female|    No|Sun|Dinner|   2|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|\n",
      "+----------+----+------+------+---+------+----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#the df is not modified b/c it was not reassigned\n",
    "df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+-------------------+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|            tip_pct|\n",
      "+----------+----+------+------+---+------+----+-------------------+\n",
      "|     16.99|1.01|Female|    No|Sun|Dinner|   2|0.05944673337257211|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|0.16054158607350097|\n",
      "|     21.01| 3.5|  Male|    No|Sun|Dinner|   3|0.16658733936220846|\n",
      "|     23.68|3.31|  Male|    No|Sun|Dinner|   2| 0.1397804054054054|\n",
      "|     24.59|3.61|Female|    No|Sun|Dinner|   4|0.14680764538430255|\n",
      "+----------+----+------+------+---+------+----+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#to get df w/ tip percentage, we have to assign to variable\n",
    "df_with_tip_pct = df.select(\"*\", col.alias('tip_pct')).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforming Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import sum, mean, concat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Built-In Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----------------+\n",
      "|        avg(tip)|  sum(total_bill)|\n",
      "+----------------+-----------------+\n",
      "|2.99827868852459|4827.769999999999|\n",
      "+----------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#use built in functions to apply them to cols\n",
    "df.select(mean(df.tip), sum(df.total_bill)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|concat(day, time)|\n",
      "+-----------------+\n",
      "|        SunDinner|\n",
      "|        SunDinner|\n",
      "|        SunDinner|\n",
      "|        SunDinner|\n",
      "|        SunDinner|\n",
      "+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#concatenate text from multiple strings together\n",
    "df.select(concat('day', 'time')).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#above doesn't look like good format, need to add space character\n",
    "# df.select(concat('day', ' ' 'time')).show(5)\n",
    "#used to concating w/ space character, but we get error \n",
    "#b/c concat func is trying to resolve everything past it as a name of a col in the df\n",
    "\n",
    "\n",
    "#Error: \n",
    "#AnalysisException: cannot resolve '` time`' given input columns: [day, sex, size, smoker, time, tip, total_bill];\n",
    "#'Project [concat(day#4, ' time) AS concat(day,  time)#295]\n",
    "#+- LogicalRDD [total_bill#0, tip#1, sex#2, smoker#3, day#4, time#5, size#6L], false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for literal (lit) function, needs import\n",
    "from pyspark.sql.functions import lit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|concat(day,  , time)|\n",
      "+--------------------+\n",
      "|          Sun Dinner|\n",
      "|          Sun Dinner|\n",
      "|          Sun Dinner|\n",
      "|          Sun Dinner|\n",
      "|          Sun Dinner|\n",
      "+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#use .lit() and it'll show proper format w/ literal space character\n",
    "df.select(concat('day', lit(' '), 'time')).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Type Casting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'CAST(tip AS STRING)'>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#similar to type casting\n",
    "df.tip.cast('string')\n",
    "#gives back col object that represents the transformation specified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[tip: string]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#apply to df w/ .select()\n",
    "df.select(df.tip.cast('string'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+\n",
      "| tip|\n",
      "+----+\n",
      "|1.01|\n",
      "|1.66|\n",
      "| 3.5|\n",
      "|3.31|\n",
      "|3.61|\n",
      "|4.71|\n",
      "| 2.0|\n",
      "|3.12|\n",
      "|1.96|\n",
      "|3.23|\n",
      "|1.71|\n",
      "| 5.0|\n",
      "|1.57|\n",
      "| 3.0|\n",
      "|3.02|\n",
      "|3.92|\n",
      "|1.67|\n",
      "|3.71|\n",
      "| 3.5|\n",
      "|3.35|\n",
      "+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#view results w/ .show()\n",
    "df.select(df.tip.cast('string')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+\n",
      "|time|\n",
      "+----+\n",
      "|null|\n",
      "|null|\n",
      "|null|\n",
      "|null|\n",
      "|null|\n",
      "|null|\n",
      "|null|\n",
      "|null|\n",
      "|null|\n",
      "|null|\n",
      "|null|\n",
      "|null|\n",
      "|null|\n",
      "|null|\n",
      "|null|\n",
      "|null|\n",
      "|null|\n",
      "|null|\n",
      "|null|\n",
      "|null|\n",
      "+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#now, try doing this to string value and cast to integer, gives back nulls\n",
    "df.select(df.time.cast('int')).show()\n",
    "#nulls are like numpy.nan or python None, to indicate absence of a value\n",
    "#theres no error, like we're used to, spark just converts to 'null'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### String Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#string manipulation w/ regex\n",
    "#apply to every value in a col\n",
    "from pyspark.sql.functions import regexp_extract, regexp_replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------+\n",
      "|regexp_extract(time, (\\w).*, 1)|\n",
      "+-------------------------------+\n",
      "|                              D|\n",
      "|                              D|\n",
      "|                              D|\n",
      "|                              D|\n",
      "|                              D|\n",
      "+-------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#extract pieces of a col (the first thing from time col)\n",
    "df.select(\n",
    "    regexp_extract('time', r'(\\w).*', 1)\n",
    ").show(5)                   #first alphanumeric char, 1 to get contents of first capture group\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|first_letter|\n",
      "+------------+\n",
      "|           D|\n",
      "|           D|\n",
      "|           D|\n",
      "|           D|\n",
      "|           D|\n",
      "+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#add alias\n",
    "df.select(\n",
    "    regexp_extract('time', r'(\\w).*', 1).alias('first_letter')\n",
    ").show(5)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------+\n",
      "|  time|first_letter|\n",
      "+------+------------+\n",
      "|Dinner|           D|\n",
      "|Dinner|           D|\n",
      "|Dinner|           D|\n",
      "|Dinner|           D|\n",
      "|Dinner|           D|\n",
      "+------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#add in original time col\n",
    "df.select(\n",
    "    'time',\n",
    "    regexp_extract('time', r'(\\w).*', 1).alias('first_letter')\n",
    ").show(5)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------+-----------------------------------+\n",
      "|  time|first_letter|regexp_replace(time, [aeiou], X, 1)|\n",
      "+------+------------+-----------------------------------+\n",
      "|Dinner|           D|                             DXnnXr|\n",
      "|Dinner|           D|                             DXnnXr|\n",
      "|Dinner|           D|                             DXnnXr|\n",
      "|Dinner|           D|                             DXnnXr|\n",
      "|Dinner|           D|                             DXnnXr|\n",
      "+------+------------+-----------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#use regexp_replace (like re.sub or .str.replace in pandas)\n",
    "df.select(\n",
    "    'time',\n",
    "    regexp_extract('time', r'(\\w).*', 1).alias('first_letter'),\n",
    "    regexp_replace('time', r'[aeiou]', 'X')\n",
    ").show(5)                #replace any of the vowels w/ a capital X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### when and otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#like case... when in sql\n",
    "#or like np.where (when it meets this condition, then do one thing)\n",
    "#or like if function in excel\n",
    "from pyspark.sql.functions import when"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[total_bill: double, tip: double, sex: string, smoker: string, day: string, time: string, size: bigint, tip_pct: double]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#modify df so that it now contains tip_pct col\n",
    "df = df.select(\n",
    "    '*',\n",
    "    (df.tip / df.total_bill).alias('tip_pct')\n",
    ")\n",
    "#adds tip percentage column\n",
    "df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+-------------------+-------------------------------------------------------------+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|            tip_pct|CASE WHEN (tip_pct > 0.2) THEN Good Tip ELSE Not Good Tip END|\n",
      "+----------+----+------+------+---+------+----+-------------------+-------------------------------------------------------------+\n",
      "|     16.99|1.01|Female|    No|Sun|Dinner|   2|0.05944673337257211|                                                 Not Good Tip|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|0.16054158607350097|                                                 Not Good Tip|\n",
      "|     21.01| 3.5|  Male|    No|Sun|Dinner|   3|0.16658733936220846|                                                 Not Good Tip|\n",
      "|     23.68|3.31|  Male|    No|Sun|Dinner|   2| 0.1397804054054054|                                                 Not Good Tip|\n",
      "|     24.59|3.61|Female|    No|Sun|Dinner|   4|0.14680764538430255|                                                 Not Good Tip|\n",
      "+----------+----+------+------+---+------+----+-------------------+-------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#now select everything \n",
    "#and when the tip_pct is greater than .2, then say 'Good tip'\n",
    "#otherwise, say 'not good tip'\n",
    "df.select(\n",
    "    '*', \n",
    "    when(df.tip_pct > .2, 'Good Tip').otherwise('Not Good Tip')\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------------+\n",
      "|            tip_pct|tip_description|\n",
      "+-------------------+---------------+\n",
      "|0.05944673337257211|   Not Good Tip|\n",
      "|0.16054158607350097|   Not Good Tip|\n",
      "|0.16658733936220846|   Not Good Tip|\n",
      "| 0.1397804054054054|   Not Good Tip|\n",
      "|0.14680764538430255|   Not Good Tip|\n",
      "|0.18623962040332148|   Not Good Tip|\n",
      "|0.22805017103762829|       Good Tip|\n",
      "|0.11607142857142858|   Not Good Tip|\n",
      "|0.13031914893617022|   Not Good Tip|\n",
      "| 0.2185385656292287|       Good Tip|\n",
      "+-------------------+---------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#to clean up above output, add alias to when/otherwise statement\n",
    "#and don't select everything, just tip_pct col instead of everything\n",
    "df.select(\n",
    "    'tip_pct', \n",
    "    (when(df.tip_pct > .2, 'Good Tip').otherwise('Not Good Tip')).alias('tip_description')\n",
    ").show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforming Rows\n",
    "#### Sorting (`.sort` or `.orderBy`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+-------------------+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|            tip_pct|\n",
      "+----------+----+------+------+---+------+----+-------------------+\n",
      "|     16.99|1.01|Female|    No|Sun|Dinner|   2|0.05944673337257211|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|0.16054158607350097|\n",
      "|     21.01| 3.5|  Male|    No|Sun|Dinner|   3|0.16658733936220846|\n",
      "|     23.68|3.31|  Male|    No|Sun|Dinner|   2| 0.1397804054054054|\n",
      "|     24.59|3.61|Female|    No|Sun|Dinner|   4|0.14680764538430255|\n",
      "|     25.29|4.71|  Male|    No|Sun|Dinner|   4|0.18623962040332148|\n",
      "|      8.77| 2.0|  Male|    No|Sun|Dinner|   2|0.22805017103762829|\n",
      "|     26.88|3.12|  Male|    No|Sun|Dinner|   4|0.11607142857142858|\n",
      "|     15.04|1.96|  Male|    No|Sun|Dinner|   2|0.13031914893617022|\n",
      "|     14.78|3.23|  Male|    No|Sun|Dinner|   2| 0.2185385656292287|\n",
      "+----------+----+------+------+---+------+----+-------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#original df\n",
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+----+------+----+-------------------+\n",
      "|total_bill| tip|   sex|smoker| day|  time|size|            tip_pct|\n",
      "+----------+----+------+------+----+------+----+-------------------+\n",
      "|      3.07| 1.0|Female|   Yes| Sat|Dinner|   1|0.32573289902280134|\n",
      "|      5.75| 1.0|Female|   Yes| Fri|Dinner|   2|0.17391304347826086|\n",
      "|      7.25| 1.0|Female|    No| Sat|Dinner|   1|0.13793103448275862|\n",
      "|      7.25|5.15|  Male|   Yes| Sun|Dinner|   2|  0.710344827586207|\n",
      "|      7.51| 2.0|  Male|    No|Thur| Lunch|   2| 0.2663115845539281|\n",
      "+----------+----+------+------+----+------+----+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#sort by total bill\n",
    "df.sort(df.total_bill).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+----+------+----+-------------------+\n",
      "|total_bill| tip|   sex|smoker| day|  time|size|            tip_pct|\n",
      "+----------+----+------+------+----+------+----+-------------------+\n",
      "|      3.07| 1.0|Female|   Yes| Sat|Dinner|   1|0.32573289902280134|\n",
      "|      5.75| 1.0|Female|   Yes| Fri|Dinner|   2|0.17391304347826086|\n",
      "|      7.25| 1.0|Female|    No| Sat|Dinner|   1|0.13793103448275862|\n",
      "|      7.25|5.15|  Male|   Yes| Sun|Dinner|   2|  0.710344827586207|\n",
      "|      7.51| 2.0|  Male|    No|Thur| Lunch|   2| 0.2663115845539281|\n",
      "+----------+----+------+------+----+------+----+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#orderBy is the same as sort\n",
    "df.orderBy(df.total_bill).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+-------------------+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|            tip_pct|\n",
      "+----------+----+------+------+---+------+----+-------------------+\n",
      "|      8.58|1.92|  Male|   Yes|Fri| Lunch|   1|0.22377622377622378|\n",
      "|     16.27| 2.5|Female|   Yes|Fri| Lunch|   2|0.15365703749231716|\n",
      "|     11.35| 2.5|Female|   Yes|Fri|Dinner|   2|0.22026431718061676|\n",
      "|     28.97| 3.0|  Male|   Yes|Fri|Dinner|   2|0.10355540214014498|\n",
      "|     22.49| 3.5|  Male|    No|Fri|Dinner|   2|0.15562472209871056|\n",
      "|     10.09| 2.0|Female|   Yes|Fri| Lunch|   2|0.19821605550049554|\n",
      "|     13.42|1.58|  Male|   Yes|Fri| Lunch|   2|0.11773472429210134|\n",
      "|     15.38| 3.0|Female|   Yes|Fri|Dinner|   2|0.19505851755526657|\n",
      "|     27.28| 4.0|  Male|   Yes|Fri|Dinner|   2|0.14662756598240467|\n",
      "|      5.75| 1.0|Female|   Yes|Fri|Dinner|   2|0.17391304347826086|\n",
      "|     12.03| 1.5|  Male|   Yes|Fri|Dinner|   2|0.12468827930174564|\n",
      "|     12.16| 2.2|  Male|   Yes|Fri| Lunch|   2|0.18092105263157895|\n",
      "|     21.01| 3.0|  Male|   Yes|Fri|Dinner|   2| 0.1427891480247501|\n",
      "|     16.32| 4.3|Female|   Yes|Fri|Dinner|   2|0.26348039215686275|\n",
      "|     12.46| 1.5|  Male|    No|Fri|Dinner|   2| 0.1203852327447833|\n",
      "|     22.75|3.25|Female|    No|Fri|Dinner|   2|0.14285714285714285|\n",
      "|     13.42|3.48|Female|   Yes|Fri| Lunch|   2| 0.2593144560357675|\n",
      "|     15.98| 3.0|Female|    No|Fri| Lunch|   3|0.18773466833541927|\n",
      "|     40.17|4.73|  Male|   Yes|Fri|Dinner|   4| 0.1177495643515061|\n",
      "|      3.07| 1.0|Female|   Yes|Sat|Dinner|   1|0.32573289902280134|\n",
      "+----------+----+------+------+---+------+----+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#sort by day and size\n",
    "df.sort(df.day, df.size).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default sort order is ascending\n",
    "#to change order, you can import new functions\n",
    "from pyspark.sql.functions import asc, desc, col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+-------------------+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|            tip_pct|\n",
      "+----------+----+------+------+---+------+----+-------------------+\n",
      "|     40.17|4.73|  Male|   Yes|Fri|Dinner|   4| 0.1177495643515061|\n",
      "|     15.98| 3.0|Female|    No|Fri| Lunch|   3|0.18773466833541927|\n",
      "|     22.49| 3.5|  Male|    No|Fri|Dinner|   2|0.15562472209871056|\n",
      "|     27.28| 4.0|  Male|   Yes|Fri|Dinner|   2|0.14662756598240467|\n",
      "|     12.03| 1.5|  Male|   Yes|Fri|Dinner|   2|0.12468827930174564|\n",
      "|     12.46| 1.5|  Male|    No|Fri|Dinner|   2| 0.1203852327447833|\n",
      "|     28.97| 3.0|  Male|   Yes|Fri|Dinner|   2|0.10355540214014498|\n",
      "|     15.38| 3.0|Female|   Yes|Fri|Dinner|   2|0.19505851755526657|\n",
      "|     22.75|3.25|Female|    No|Fri|Dinner|   2|0.14285714285714285|\n",
      "|     12.16| 2.2|  Male|   Yes|Fri| Lunch|   2|0.18092105263157895|\n",
      "|     16.27| 2.5|Female|   Yes|Fri| Lunch|   2|0.15365703749231716|\n",
      "|     13.42|3.48|Female|   Yes|Fri| Lunch|   2| 0.2593144560357675|\n",
      "|     21.01| 3.0|  Male|   Yes|Fri|Dinner|   2| 0.1427891480247501|\n",
      "|     10.09| 2.0|Female|   Yes|Fri| Lunch|   2|0.19821605550049554|\n",
      "|     11.35| 2.5|Female|   Yes|Fri|Dinner|   2|0.22026431718061676|\n",
      "|      5.75| 1.0|Female|   Yes|Fri|Dinner|   2|0.17391304347826086|\n",
      "|     13.42|1.58|  Male|   Yes|Fri| Lunch|   2|0.11773472429210134|\n",
      "|     16.32| 4.3|Female|   Yes|Fri|Dinner|   2|0.26348039215686275|\n",
      "|      8.58|1.92|  Male|   Yes|Fri| Lunch|   1|0.22377622377622378|\n",
      "|     28.15| 3.0|  Male|   Yes|Sat|Dinner|   5|0.10657193605683837|\n",
      "+----------+----+------+------+---+------+----+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#sort by day (default=ascending), descending size\n",
    "df.sort(df.day, desc('size')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+-------------------+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|            tip_pct|\n",
      "+----------+----+------+------+---+------+----+-------------------+\n",
      "|     40.17|4.73|  Male|   Yes|Fri|Dinner|   4| 0.1177495643515061|\n",
      "|     16.32| 4.3|Female|   Yes|Fri|Dinner|   2|0.26348039215686275|\n",
      "|     12.03| 1.5|  Male|   Yes|Fri|Dinner|   2|0.12468827930174564|\n",
      "|     27.28| 4.0|  Male|   Yes|Fri|Dinner|   2|0.14662756598240467|\n",
      "|     22.49| 3.5|  Male|    No|Fri|Dinner|   2|0.15562472209871056|\n",
      "|     21.01| 3.0|  Male|   Yes|Fri|Dinner|   2| 0.1427891480247501|\n",
      "|      5.75| 1.0|Female|   Yes|Fri|Dinner|   2|0.17391304347826086|\n",
      "|     12.46| 1.5|  Male|    No|Fri|Dinner|   2| 0.1203852327447833|\n",
      "|     11.35| 2.5|Female|   Yes|Fri|Dinner|   2|0.22026431718061676|\n",
      "|     22.75|3.25|Female|    No|Fri|Dinner|   2|0.14285714285714285|\n",
      "|     15.38| 3.0|Female|   Yes|Fri|Dinner|   2|0.19505851755526657|\n",
      "|     28.97| 3.0|  Male|   Yes|Fri|Dinner|   2|0.10355540214014498|\n",
      "|     15.98| 3.0|Female|    No|Fri| Lunch|   3|0.18773466833541927|\n",
      "|     13.42|3.48|Female|   Yes|Fri| Lunch|   2| 0.2593144560357675|\n",
      "|     12.16| 2.2|  Male|   Yes|Fri| Lunch|   2|0.18092105263157895|\n",
      "|     10.09| 2.0|Female|   Yes|Fri| Lunch|   2|0.19821605550049554|\n",
      "|     13.42|1.58|  Male|   Yes|Fri| Lunch|   2|0.11773472429210134|\n",
      "|     16.27| 2.5|Female|   Yes|Fri| Lunch|   2|0.15365703749231716|\n",
      "|      8.58|1.92|  Male|   Yes|Fri| Lunch|   1|0.22377622377622378|\n",
      "|     28.15| 3.0|  Male|   Yes|Sat|Dinner|   5|0.10657193605683837|\n",
      "+----------+----+------+------+---+------+----+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#add ascending time\n",
    "df.sort(df.day, asc('time'), desc('size')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'new'>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#col function creates a spark col(expression that represents a col) (not w/ data)\n",
    "col('new')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'new AS `new`'>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from new col object, we can call various methods (add alias)\n",
    "col('new').alias('new')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'new ASC NULLS FIRST'>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ascending \n",
    "col('new').asc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'new DESC NULLS LAST'>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#or descending\n",
    "col('new').desc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+----+------+----+-------------------+\n",
      "|total_bill| tip|   sex|smoker| day|  time|size|            tip_pct|\n",
      "+----------+----+------+------+----+------+----+-------------------+\n",
      "|     48.17| 5.0|  Male|    No| Sun|Dinner|   6|0.10379904504878555|\n",
      "|      29.8| 4.2|Female|    No|Thur| Lunch|   6|0.14093959731543623|\n",
      "|     27.05| 5.0|Female|    No|Thur| Lunch|   6|0.18484288354898337|\n",
      "|      34.3| 6.7|  Male|    No|Thur| Lunch|   6|0.19533527696793004|\n",
      "|     30.46| 2.0|  Male|   Yes| Sun|Dinner|   5|0.06565988181221273|\n",
      "|     29.85|5.14|Female|    No| Sun|Dinner|   5| 0.1721943048576214|\n",
      "|     28.15| 3.0|  Male|   Yes| Sat|Dinner|   5|0.10657193605683837|\n",
      "|     20.69| 5.0|  Male|    No| Sun|Dinner|   5| 0.2416626389560174|\n",
      "|     41.19| 5.0|  Male|    No|Thur| Lunch|   5|0.12138868657441128|\n",
      "|     30.14|3.09|Female|   Yes| Sat|Dinner|   4|0.10252156602521566|\n",
      "|     19.77| 2.0|  Male|    No| Sun|Dinner|   4|0.10116337885685382|\n",
      "|     25.89|5.16|  Male|   Yes| Sat|Dinner|   4| 0.1993047508690614|\n",
      "|      25.0|3.75|Female|    No| Sun|Dinner|   4|               0.15|\n",
      "|     38.73| 3.0|  Male|   Yes| Sat|Dinner|   4| 0.0774593338497289|\n",
      "|     34.65|3.68|  Male|   Yes| Sun|Dinner|   4|0.10620490620490622|\n",
      "|     24.55| 2.0|  Male|    No| Sun|Dinner|   4| 0.0814663951120163|\n",
      "|     23.17| 6.5|  Male|   Yes| Sun|Dinner|   4| 0.2805351747949935|\n",
      "|     20.45| 3.0|  Male|    No| Sat|Dinner|   4| 0.1466992665036675|\n",
      "|      21.5| 3.5|  Male|    No| Sun|Dinner|   4|0.16279069767441862|\n",
      "|     31.71| 4.5|  Male|    No| Sun|Dinner|   4|0.14191106906338694|\n",
      "+----------+----+------+------+----+------+----+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#sort by size col desc, and then time ascending\n",
    "df.sort(col('size').desc(), col('time')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtering (`.where` or `.filter`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+-------------------+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|            tip_pct|\n",
      "+----------+----+------+------+---+------+----+-------------------+\n",
      "|     16.99|1.01|Female|    No|Sun|Dinner|   2|0.05944673337257211|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|0.16054158607350097|\n",
      "|     21.01| 3.5|  Male|    No|Sun|Dinner|   3|0.16658733936220846|\n",
      "|     23.68|3.31|  Male|    No|Sun|Dinner|   2| 0.1397804054054054|\n",
      "|     24.59|3.61|Female|    No|Sun|Dinner|   4|0.14680764538430255|\n",
      "|      8.77| 2.0|  Male|    No|Sun|Dinner|   2|0.22805017103762829|\n",
      "|     26.88|3.12|  Male|    No|Sun|Dinner|   4|0.11607142857142858|\n",
      "|     15.04|1.96|  Male|    No|Sun|Dinner|   2|0.13031914893617022|\n",
      "|     14.78|3.23|  Male|    No|Sun|Dinner|   2| 0.2185385656292287|\n",
      "|     10.27|1.71|  Male|    No|Sun|Dinner|   2| 0.1665043816942551|\n",
      "|     15.42|1.57|  Male|    No|Sun|Dinner|   2|0.10181582360570687|\n",
      "|     18.43| 3.0|  Male|    No|Sun|Dinner|   4|0.16277807921866522|\n",
      "|     14.83|3.02|Female|    No|Sun|Dinner|   2|0.20364126770060686|\n",
      "|     21.58|3.92|  Male|    No|Sun|Dinner|   2|0.18164967562557924|\n",
      "|     10.33|1.67|Female|    No|Sun|Dinner|   3| 0.1616650532429816|\n",
      "|     16.29|3.71|  Male|    No|Sun|Dinner|   3|0.22774708410067526|\n",
      "|     16.97| 3.5|Female|    No|Sun|Dinner|   3|0.20624631703005306|\n",
      "|     20.65|3.35|  Male|    No|Sat|Dinner|   3|0.16222760290556903|\n",
      "|     20.29|2.75|Female|    No|Sat|Dinner|   2|0.13553474618038444|\n",
      "|     15.77|2.23|Female|    No|Sat|Dinner|   2|0.14140773620798985|\n",
      "+----------+----+------+------+---+------+----+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#where tip is less than 4\n",
    "df.where(df.tip < 4).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+-------------------+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|            tip_pct|\n",
      "+----------+----+------+------+---+------+----+-------------------+\n",
      "|     16.99|1.01|Female|    No|Sun|Dinner|   2|0.05944673337257211|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|0.16054158607350097|\n",
      "|     21.01| 3.5|  Male|    No|Sun|Dinner|   3|0.16658733936220846|\n",
      "|     23.68|3.31|  Male|    No|Sun|Dinner|   2| 0.1397804054054054|\n",
      "|     24.59|3.61|Female|    No|Sun|Dinner|   4|0.14680764538430255|\n",
      "|      8.77| 2.0|  Male|    No|Sun|Dinner|   2|0.22805017103762829|\n",
      "|     26.88|3.12|  Male|    No|Sun|Dinner|   4|0.11607142857142858|\n",
      "|     15.04|1.96|  Male|    No|Sun|Dinner|   2|0.13031914893617022|\n",
      "|     14.78|3.23|  Male|    No|Sun|Dinner|   2| 0.2185385656292287|\n",
      "|     10.27|1.71|  Male|    No|Sun|Dinner|   2| 0.1665043816942551|\n",
      "|     15.42|1.57|  Male|    No|Sun|Dinner|   2|0.10181582360570687|\n",
      "|     18.43| 3.0|  Male|    No|Sun|Dinner|   4|0.16277807921866522|\n",
      "|     14.83|3.02|Female|    No|Sun|Dinner|   2|0.20364126770060686|\n",
      "|     21.58|3.92|  Male|    No|Sun|Dinner|   2|0.18164967562557924|\n",
      "|     10.33|1.67|Female|    No|Sun|Dinner|   3| 0.1616650532429816|\n",
      "|     16.29|3.71|  Male|    No|Sun|Dinner|   3|0.22774708410067526|\n",
      "|     16.97| 3.5|Female|    No|Sun|Dinner|   3|0.20624631703005306|\n",
      "|     20.65|3.35|  Male|    No|Sat|Dinner|   3|0.16222760290556903|\n",
      "|     20.29|2.75|Female|    No|Sat|Dinner|   2|0.13553474618038444|\n",
      "|     15.77|2.23|Female|    No|Sat|Dinner|   2|0.14140773620798985|\n",
      "+----------+----+------+------+---+------+----+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#to show results of bool expression (df.tip <4)\n",
    "mask = df.tip < 4\n",
    "df.where(mask).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+----+------+----+-------------------+\n",
      "|total_bill| tip|   sex|smoker| day|  time|size|            tip_pct|\n",
      "+----------+----+------+------+----+------+----+-------------------+\n",
      "|      12.6| 1.0|  Male|   Yes| Sat|Dinner|   2|0.07936507936507936|\n",
      "|      5.75| 1.0|Female|   Yes| Fri|Dinner|   2|0.17391304347826086|\n",
      "|      7.25| 1.0|Female|    No| Sat|Dinner|   1|0.13793103448275862|\n",
      "|      3.07| 1.0|Female|   Yes| Sat|Dinner|   1|0.32573289902280134|\n",
      "|     16.99|1.01|Female|    No| Sun|Dinner|   2|0.05944673337257211|\n",
      "|      12.9| 1.1|Female|   Yes| Sat|Dinner|   2|0.08527131782945736|\n",
      "|     32.83|1.17|  Male|   Yes| Sat|Dinner|   2|0.03563813585135547|\n",
      "|     10.07|1.25|  Male|    No| Sat|Dinner|   2|0.12413108242303872|\n",
      "|     10.51|1.25|  Male|    No| Sat|Dinner|   2|0.11893434823977164|\n",
      "|      8.51|1.25|Female|    No|Thur| Lunch|   2|0.14688601645123384|\n",
      "|      9.68|1.32|  Male|    No| Sun|Dinner|   2|0.13636363636363638|\n",
      "|     18.64|1.36|Female|    No|Thur| Lunch|   3|0.07296137339055794|\n",
      "|      7.74|1.44|  Male|   Yes| Sat|Dinner|   2|0.18604651162790697|\n",
      "|      7.56|1.44|  Male|    No|Thur| Lunch|   2|0.19047619047619047|\n",
      "|      9.55|1.45|  Male|    No| Sat|Dinner|   2| 0.1518324607329843|\n",
      "|     10.77|1.47|  Male|    No| Sat|Dinner|   2|0.13649025069637882|\n",
      "|      8.52|1.48|  Male|    No|Thur| Lunch|   2|0.17370892018779344|\n",
      "|      8.35| 1.5|Female|    No|Thur| Lunch|   2|0.17964071856287425|\n",
      "|     11.59| 1.5|  Male|   Yes| Sat|Dinner|   2|0.12942191544434858|\n",
      "|     11.17| 1.5|Female|    No|Thur| Lunch|   2|0.13428827215756492|\n",
      "+----------+----+------+------+----+------+----+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#.filter is same as .where\n",
    "#can combine expressions w/ operators from np arrays or pd Series\n",
    "#where time is dinner OR tip is less than or equal to 2\n",
    "#add sort by tip and show\n",
    "df.filter((df.time == \"Dinner\") | (df.tip <= 2)).sort('tip').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+-------------------+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|            tip_pct|\n",
      "+----------+----+------+------+---+------+----+-------------------+\n",
      "|     38.01| 3.0|  Male|   Yes|Sat|Dinner|   4|0.07892659826361484|\n",
      "|     11.24|1.76|  Male|   Yes|Sat|Dinner|   2|0.15658362989323843|\n",
      "|     20.29|3.21|  Male|   Yes|Sat|Dinner|   2| 0.1582060128141942|\n",
      "|     13.81| 2.0|  Male|   Yes|Sat|Dinner|   2| 0.1448225923244026|\n",
      "|     11.02|1.98|  Male|   Yes|Sat|Dinner|   2|0.17967332123411978|\n",
      "|     18.29|3.76|  Male|   Yes|Sat|Dinner|   4|0.20557681793329688|\n",
      "|      3.07| 1.0|Female|   Yes|Sat|Dinner|   1|0.32573289902280134|\n",
      "|     15.01|2.09|  Male|   Yes|Sat|Dinner|   2|0.13924050632911392|\n",
      "|     26.86|3.14|Female|   Yes|Sat|Dinner|   2|0.11690245718540582|\n",
      "|     25.28| 5.0|Female|   Yes|Sat|Dinner|   2|0.19778481012658228|\n",
      "|     17.92|3.08|  Male|   Yes|Sat|Dinner|   2|           0.171875|\n",
      "|      44.3| 2.5|Female|   Yes|Sat|Dinner|   3|0.05643340857787811|\n",
      "|     22.42|3.48|Female|   Yes|Sat|Dinner|   2|0.15521855486173058|\n",
      "|     15.36|1.64|  Male|   Yes|Sat|Dinner|   2|0.10677083333333333|\n",
      "|     20.49|4.06|  Male|   Yes|Sat|Dinner|   2|0.19814543679843827|\n",
      "|     25.21|4.29|  Male|   Yes|Sat|Dinner|   2| 0.1701705672352241|\n",
      "|     14.31| 4.0|Female|   Yes|Sat|Dinner|   2| 0.2795248078266946|\n",
      "|     10.59|1.61|Female|   Yes|Sat|Dinner|   2|0.15203021718602455|\n",
      "|     10.63| 2.0|Female|   Yes|Sat|Dinner|   2|0.18814675446848542|\n",
      "|     50.81|10.0|  Male|   Yes|Sat|Dinner|   3|0.19681165124975397|\n",
      "+----------+----+------+------+---+------+----+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#can do multiple .where's (equivalent to AND)\n",
    "#where smoker is Yes AND where day is Sat\n",
    "df.where(df.smoker == \"Yes\").where(df.day == \"Sat\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import mean, min, max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `.groupBy` and `.agg`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------------+\n",
      "|  time|          avg(tip)|\n",
      "+------+------------------+\n",
      "| Lunch|2.7280882352941176|\n",
      "|Dinner| 3.102670454545455|\n",
      "+------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#group by time and call .agg to get the mean of tip for each time\n",
    "df.groupBy('time').agg(mean('tip')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+------------------+--------+\n",
      "|  time|min(tip)|          avg(tip)|max(tip)|\n",
      "+------+--------+------------------+--------+\n",
      "| Lunch|    1.25|2.7280882352941176|     6.7|\n",
      "|Dinner|     1.0| 3.102670454545455|    10.0|\n",
      "+------+--------+------------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#supply multiple arguments to .agg function\n",
    "df.groupBy('time').agg(min('tip'), mean('tip'), max('tip')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------------+\n",
      "|  time|           avg_tip|\n",
      "+------+------------------+\n",
      "| Lunch|2.7280882352941176|\n",
      "|Dinner| 3.102670454545455|\n",
      "+------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#add .alias to rename average tip \n",
    "df.groupBy('time').agg(mean('tip').alias('avg_tip')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+------------------+\n",
      "|  time| day|   avg(total_bill)|\n",
      "+------+----+------------------+\n",
      "| Lunch|Thur|17.664754098360653|\n",
      "|Dinner|Thur|             18.78|\n",
      "| Lunch| Fri|12.845714285714285|\n",
      "|Dinner| Fri| 19.66333333333333|\n",
      "|Dinner| Sun|21.409999999999997|\n",
      "|Dinner| Sat|20.441379310344825|\n",
      "+------+----+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#multiple subgroups and see average total bill for each one of them\n",
    "df.groupBy('time', 'day').agg(mean('total_bill')).show()\n",
    "\n",
    "#with spark, pass cols as arguments, not in a list like in pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `.crosstab` and `.pivot`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+---+---+----+\n",
      "|time_day|Fri|Sat|Sun|Thur|\n",
      "+--------+---+---+---+----+\n",
      "|   Lunch|  7|  0|  0|  61|\n",
      "|  Dinner| 12| 87| 76|   1|\n",
      "+--------+---+---+---+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#crosstab time and day (pass each col as a separate argument, not a list)\n",
    "df.crosstab('time', 'day').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------------+------------------+------------------+------------------+\n",
      "|  time|               Fri|               Sat|               Sun|              Thur|\n",
      "+------+------------------+------------------+------------------+------------------+\n",
      "| Lunch|12.845714285714285|              null|              null|17.664754098360653|\n",
      "|Dinner| 19.66333333333333|20.441379310344825|21.409999999999997|             18.78|\n",
      "+------+------------------+------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#.pivot turns argument into columns and we can see the avg total bill for lunch or dinner per day\n",
    "df.groupBy('time').pivot('day').agg(mean('total_bill')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: \n",
    "- `.crosstab` is just for counts\n",
    "- for other methods of summarizing groups, use `.groupBy` (maybe in combination with `.pivot`) + `.agg`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Spark Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spark SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a view in spark\n",
    "#exists for duration of spark session\n",
    "df.createOrReplaceTempView('tips')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+-------------------+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|            tip_pct|\n",
      "+----------+----+------+------+---+------+----+-------------------+\n",
      "|     16.99|1.01|Female|    No|Sun|Dinner|   2|0.05944673337257211|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|0.16054158607350097|\n",
      "|     21.01| 3.5|  Male|    No|Sun|Dinner|   3|0.16658733936220846|\n",
      "|     23.68|3.31|  Male|    No|Sun|Dinner|   2| 0.1397804054054054|\n",
      "|     24.59|3.61|Female|    No|Sun|Dinner|   4|0.14680764538430255|\n",
      "|     25.29|4.71|  Male|    No|Sun|Dinner|   4|0.18623962040332148|\n",
      "|      8.77| 2.0|  Male|    No|Sun|Dinner|   2|0.22805017103762829|\n",
      "|     26.88|3.12|  Male|    No|Sun|Dinner|   4|0.11607142857142858|\n",
      "|     15.04|1.96|  Male|    No|Sun|Dinner|   2|0.13031914893617022|\n",
      "|     14.78|3.23|  Male|    No|Sun|Dinner|   2| 0.2185385656292287|\n",
      "|     10.27|1.71|  Male|    No|Sun|Dinner|   2| 0.1665043816942551|\n",
      "|     35.26| 5.0|Female|    No|Sun|Dinner|   4|0.14180374361883155|\n",
      "|     15.42|1.57|  Male|    No|Sun|Dinner|   2|0.10181582360570687|\n",
      "|     18.43| 3.0|  Male|    No|Sun|Dinner|   4|0.16277807921866522|\n",
      "|     14.83|3.02|Female|    No|Sun|Dinner|   2|0.20364126770060686|\n",
      "|     21.58|3.92|  Male|    No|Sun|Dinner|   2|0.18164967562557924|\n",
      "|     10.33|1.67|Female|    No|Sun|Dinner|   3| 0.1616650532429816|\n",
      "|     16.29|3.71|  Male|    No|Sun|Dinner|   3|0.22774708410067526|\n",
      "|     16.97| 3.5|Female|    No|Sun|Dinner|   3|0.20624631703005306|\n",
      "|     20.65|3.35|  Male|    No|Sat|Dinner|   3|0.16222760290556903|\n",
      "+----------+----+------+------+---+------+----+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#above function let's us use sql\n",
    "spark.sql('''\n",
    "SELECT *\n",
    "FROM tips\n",
    "''').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+---+\n",
      "| tip|total_bill|day|\n",
      "+----+----------+---+\n",
      "|3.35|     20.65|Sat|\n",
      "|4.08|     17.92|Sat|\n",
      "|2.75|     20.29|Sat|\n",
      "|2.23|     15.77|Sat|\n",
      "|7.58|     39.42|Sat|\n",
      "|3.18|     19.82|Sat|\n",
      "|2.34|     17.81|Sat|\n",
      "| 2.0|     13.37|Sat|\n",
      "| 2.0|     12.69|Sat|\n",
      "| 4.3|      21.7|Sat|\n",
      "| 3.0|     19.65|Sat|\n",
      "|1.45|      9.55|Sat|\n",
      "| 2.5|     18.35|Sat|\n",
      "| 3.0|     15.06|Sat|\n",
      "|2.45|     20.69|Sat|\n",
      "|3.27|     17.78|Sat|\n",
      "| 3.6|     24.06|Sat|\n",
      "| 2.0|     16.31|Sat|\n",
      "|3.07|     16.93|Sat|\n",
      "|2.31|     18.69|Sat|\n",
      "+----+----------+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#find the tip, total_bill, and day with the highest overall sales for that day\n",
    "spark.sql('''\n",
    "SELECT tip, total_bill, day\n",
    "FROM tips\n",
    "WHERE day = (\n",
    "    SELECT day\n",
    "    FROM tips\n",
    "    GROUP BY day\n",
    "    ORDER BY sum(total_bill) DESC\n",
    "    LIMIT 1\n",
    ")    \n",
    "''').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `.explain()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(1) Project [total_bill#0, tip#1, sex#2, smoker#3, day#4, time#5, size#6L, (tip#1 / total_bill#0) AS tip_pct#362]\n",
      "+- *(1) Scan ExistingRDD[total_bill#0,tip#1,sex#2,smoker#3,day#4,time#5,size#6L]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#.explain gets back results from spark's query planner\n",
    "spark.sql('''\n",
    "SELECT *\n",
    "FROM tips    \n",
    "''').explain()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**query planner = the way the query is going to be executed**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(1) Project [total_bill#0, tip#1, sex#2, smoker#3, day#4, time#5, size#6L, (tip#1 / total_bill#0) AS tip_pct#362, (tip#1 / total_bill#0) AS tip_pct#1254]\n",
      "+- *(1) Scan ExistingRDD[total_bill#0,tip#1,sex#2,smoker#3,day#4,time#5,size#6L]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#query plan reads from bottom to top\n",
    "#first, takes existing RDD (existing df that was turned from pandas df into spark df)\n",
    "#then, Project operation, where it selects all of our columns, and also tip / total_bill as tip_pct\n",
    "df.select(\n",
    "    '*',\n",
    "    (df.tip / df.total_bill).alias('tip_pct'),\n",
    ").explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(1) Project [total_bill#0, tip#1, sex#2, smoker#3, day#4, time#5, size#6L, (tip#1 / total_bill#0) AS tip_pct#362, (tip#1 / total_bill#0) AS tip_pct#1264]\n",
      "+- *(1) Filter (isnotnull(time#5) AND (time#5 = Dinner))\n",
      "   +- *(1) Scan ExistingRDD[total_bill#0,tip#1,sex#2,smoker#3,day#4,time#5,size#6L]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#add .where(time == Dinner)\n",
    "#first take from existing dataset, then we do a filter where time is not null and == Dinner\n",
    "#and then do Project where we say take all cols and create tip_pct col\n",
    "df.where(\n",
    "    df.time == 'Dinner'\n",
    ").select(\n",
    "    '*',\n",
    "    (df.tip / df.total_bill).alias('tip_pct'),\n",
    ").explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(1) Project [total_bill#0, tip#1, sex#2, smoker#3, day#4, time#5, size#6L, (tip#1 / total_bill#0) AS tip_pct#362, (tip#1 / total_bill#0) AS tip_pct#1274]\n",
      "+- *(1) Filter (isnotnull(time#5) AND (time#5 = Dinner))\n",
      "   +- *(1) Scan ExistingRDD[total_bill#0,tip#1,sex#2,smoker#3,day#4,time#5,size#6L]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#what if we do select first, and then .where()?\n",
    "df.select(\n",
    "    '*',\n",
    "    (df.tip / df.total_bill).alias('tip_pct'),\n",
    ").where(\n",
    "    df.time == 'Dinner'\n",
    ").explain()\n",
    "\n",
    "#the same output comes out cause spark figures out the most efficient way to do things"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing Data\n",
    "Tips dataset does not have any missing info but syntax looks like this:\n",
    "\n",
    "\n",
    ">`df.na.drop()`\n",
    "\n",
    ">`df.na.drop(subset=['x', 'y'])`\n",
    "\n",
    "Or to fill in data w/ specific number:\n",
    "\n",
    "\n",
    ">`df.na.fill(0)`\n",
    "\n",
    ">`df.na.fill(0, subset=['x', 'y'])`\n",
    "\n",
    "\n",
    "\n",
    "*`.subset=['col1', 'col2']` restricts this to only columns specified*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `expr` lets us mix in parts of SQL into our dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import expr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+-------------------+-------------------+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|            tip_pct|            tip_pct|\n",
      "+----------+----+------+------+---+------+----+-------------------+-------------------+\n",
      "|     16.99|1.01|Female|    No|Sun|Dinner|   2|0.05944673337257211|0.05944673337257211|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|0.16054158607350097|0.16054158607350097|\n",
      "|     21.01| 3.5|  Male|    No|Sun|Dinner|   3|0.16658733936220846|0.16658733936220846|\n",
      "|     23.68|3.31|  Male|    No|Sun|Dinner|   2| 0.1397804054054054| 0.1397804054054054|\n",
      "|     24.59|3.61|Female|    No|Sun|Dinner|   4|0.14680764538430255|0.14680764538430255|\n",
      "|     25.29|4.71|  Male|    No|Sun|Dinner|   4|0.18623962040332148|0.18623962040332148|\n",
      "|      8.77| 2.0|  Male|    No|Sun|Dinner|   2|0.22805017103762829|0.22805017103762829|\n",
      "|     26.88|3.12|  Male|    No|Sun|Dinner|   4|0.11607142857142858|0.11607142857142858|\n",
      "|     15.04|1.96|  Male|    No|Sun|Dinner|   2|0.13031914893617022|0.13031914893617022|\n",
      "|     14.78|3.23|  Male|    No|Sun|Dinner|   2| 0.2185385656292287| 0.2185385656292287|\n",
      "|     10.27|1.71|  Male|    No|Sun|Dinner|   2| 0.1665043816942551| 0.1665043816942551|\n",
      "|     35.26| 5.0|Female|    No|Sun|Dinner|   4|0.14180374361883155|0.14180374361883155|\n",
      "|     15.42|1.57|  Male|    No|Sun|Dinner|   2|0.10181582360570687|0.10181582360570687|\n",
      "|     18.43| 3.0|  Male|    No|Sun|Dinner|   4|0.16277807921866522|0.16277807921866522|\n",
      "|     14.83|3.02|Female|    No|Sun|Dinner|   2|0.20364126770060686|0.20364126770060686|\n",
      "|     21.58|3.92|  Male|    No|Sun|Dinner|   2|0.18164967562557924|0.18164967562557924|\n",
      "|     10.33|1.67|Female|    No|Sun|Dinner|   3| 0.1616650532429816| 0.1616650532429816|\n",
      "|     16.29|3.71|  Male|    No|Sun|Dinner|   3|0.22774708410067526|0.22774708410067526|\n",
      "|     16.97| 3.5|Female|    No|Sun|Dinner|   3|0.20624631703005306|0.20624631703005306|\n",
      "|     17.46|2.54|  Male|    No|Sun|Dinner|   2|0.14547537227949597|0.14547537227949597|\n",
      "+----------+----+------+------+---+------+----+-------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#instead of writing spark.sql\n",
    "#mix in sql expressions as part of df\n",
    "df.select(\n",
    "    '*',\n",
    "    expr('tip / total_bill as tip_pct')\n",
    ").where(\n",
    "    expr('day = \"Sun\" AND time = \"Dinner\"')\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Spark API Mini Exercises\n",
    "Copy the code below to create a pandas dataframe with 20 rows and 3 columns:\n",
    "\n",
    "`import pandas as pd\n",
    "import numpy as np`\n",
    "\n",
    "`np.random.seed(13)`\n",
    "\n",
    "`pandas_dataframe = pd.DataFrame({\n",
    "    \"n\": np.random.randn(20),\n",
    "    \"group\": np.random.choice(list(\"xyz\"), 20),\n",
    "    \"abool\": np.random.choice([True, False], 20),\n",
    "})`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Spark Dataframe Basics\n",
    "\n",
    "#### i. Use the starter code above to create a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_dataframe = pd.DataFrame({\n",
    "    \"n\": np.random.randn(20),\n",
    "    \"group\": np.random.choice(list(\"xyz\"), 20),\n",
    "    \"abool\": np.random.choice([True, False], 20),\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ii. Convert the pandas dataframe to a spark dataframe. From this point forward, do all of your work with the spark dataframe, not the pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[n: double, group: string, abool: boolean]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.createDataFrame(pandas_dataframe)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+-----+\n",
      "|summary|                  n|group|\n",
      "+-------+-------------------+-----+\n",
      "|  count|                 20|   20|\n",
      "|   mean|0.36640264498852165| null|\n",
      "| stddev| 0.8905322898155364| null|\n",
      "|    min| -1.261605945319069|    x|\n",
      "|    max| 2.1503829673811126|    z|\n",
      "+-------+-------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#can see summary stats w/ .describe()\n",
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### iii. Show the first 3 rows of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-----+\n",
      "|                   n|group|abool|\n",
      "+--------------------+-----+-----+\n",
      "|  -0.712390662050588|    z|false|\n",
      "|   0.753766378659703|    x|false|\n",
      "|-0.04450307833805...|    z|false|\n",
      "+--------------------+-----+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### iv. Show the first 7 rows of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-----+\n",
      "|                   n|group|abool|\n",
      "+--------------------+-----+-----+\n",
      "|  -0.712390662050588|    z|false|\n",
      "|   0.753766378659703|    x|false|\n",
      "|-0.04450307833805...|    z|false|\n",
      "| 0.45181233874578974|    y|false|\n",
      "|  1.3451017084510097|    z|false|\n",
      "|  0.5323378882945463|    y|false|\n",
      "|  1.3501878997225267|    z|false|\n",
      "+--------------------+-----+-----+\n",
      "only showing top 7 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### v. View a summary of the data using `.describe`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+-----+\n",
      "|summary|                  n|group|\n",
      "+-------+-------------------+-----+\n",
      "|  count|                 20|   20|\n",
      "|   mean|0.36640264498852165| null|\n",
      "| stddev| 0.8905322898155364| null|\n",
      "|    min| -1.261605945319069|    x|\n",
      "|    max| 2.1503829673811126|    z|\n",
      "+-------+-------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### vi. Use `.select` to create a new dataframe with just the `n` and `abool` columns. View the first 5 rows of this dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|                   n|abool|\n",
      "+--------------------+-----+\n",
      "|  -0.712390662050588|false|\n",
      "|   0.753766378659703|false|\n",
      "|-0.04450307833805...|false|\n",
      "| 0.45181233874578974|false|\n",
      "|  1.3451017084510097|false|\n",
      "+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('n', 'abool').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### vii. Use `.select` to create a new dataframe with just the `group` and `abool` columns. View the first 5 rows of this dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|group|abool|\n",
      "+-----+-----+\n",
      "|    z|false|\n",
      "|    x|false|\n",
      "|    z|false|\n",
      "|    y|false|\n",
      "|    z|false|\n",
      "+-----+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('group', 'abool').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### viii. Use `.select` to create a new dataframe with the `group` column and the `abool` column renamed to `a_boolean_value`. Show the first 3 rows of this dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------------+\n",
      "|group|a_boolean_value|\n",
      "+-----+---------------+\n",
      "|    z|          false|\n",
      "|    x|          false|\n",
      "|    z|          false|\n",
      "+-----+---------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('group', df.abool.alias('a_boolean_value')).show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ix. Use `.select` to create a new dataframe with the `group` column and the `n` column renamed to `a_numeric_value`. Show the first 6 rows of this dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|group|     a_numeric_value|\n",
      "+-----+--------------------+\n",
      "|    z|  -0.712390662050588|\n",
      "|    x|   0.753766378659703|\n",
      "|    z|-0.04450307833805...|\n",
      "|    y| 0.45181233874578974|\n",
      "|    z|  1.3451017084510097|\n",
      "|    y|  0.5323378882945463|\n",
      "+-----+--------------------+\n",
      "only showing top 6 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('group', df.n.alias('a_numeric_value')).show(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-----+\n",
      "|                   n|group|abool|\n",
      "+--------------------+-----+-----+\n",
      "|  -0.712390662050588|    z|false|\n",
      "|   0.753766378659703|    x|false|\n",
      "|-0.04450307833805...|    z|false|\n",
      "| 0.45181233874578974|    y|false|\n",
      "|  1.3451017084510097|    z|false|\n",
      "+--------------------+-----+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#nothing has been reassigned so df is still like original\n",
    "#none of changes above were saved to a new variable\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Column Manipulation\n",
    "\n",
    "#### i. Use the starter code above to re-create a spark dataframe. Store the spark dataframe in a variable named `df`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-----+\n",
      "|                   n|group|abool|\n",
      "+--------------------+-----+-----+\n",
      "|  -0.712390662050588|    z|false|\n",
      "|   0.753766378659703|    x|false|\n",
      "|-0.04450307833805...|    z|false|\n",
      "| 0.45181233874578974|    y|false|\n",
      "|  1.3451017084510097|    z|false|\n",
      "|  0.5323378882945463|    y|false|\n",
      "|  1.3501878997225267|    z|false|\n",
      "|  0.8612113741693206|    x|false|\n",
      "|  1.4786857374358966|    z| true|\n",
      "| -1.0453771305385342|    y| true|\n",
      "| -0.7889890249515489|    x|false|\n",
      "|  -1.261605945319069|    y|false|\n",
      "|  0.5628467852810314|    y| true|\n",
      "|-0.24332625188556253|    y| true|\n",
      "|  0.9137407048596775|    y|false|\n",
      "| 0.31735092273633597|    x|false|\n",
      "| 0.12730328020698067|    z|false|\n",
      "|  2.1503829673811126|    y| true|\n",
      "|  0.6062886568962988|    x|false|\n",
      "|-0.02677164998644...|    x| true|\n",
      "+--------------------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ii. Use `.select` to add 4 to the `n` column. Show the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|           (n + 4)|\n",
      "+------------------+\n",
      "|3.2876093379494122|\n",
      "| 4.753766378659703|\n",
      "|3.9554969216619464|\n",
      "|  4.45181233874579|\n",
      "|5.3451017084510095|\n",
      "| 4.532337888294546|\n",
      "| 5.350187899722527|\n",
      "|  4.86121137416932|\n",
      "| 5.478685737435897|\n",
      "| 2.954622869461466|\n",
      "|3.2110109750484512|\n",
      "| 2.738394054680931|\n",
      "| 4.562846785281032|\n",
      "|3.7566737481144377|\n",
      "| 4.913740704859677|\n",
      "| 4.317350922736336|\n",
      "| 4.127303280206981|\n",
      "| 6.150382967381113|\n",
      "| 4.606288656896298|\n",
      "|3.9732283500135592|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df.n + 4).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### iii. Subtract 5 from the `n` column and view the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|            (n - 5)|\n",
      "+-------------------+\n",
      "| -5.712390662050588|\n",
      "| -4.246233621340297|\n",
      "| -5.044503078338053|\n",
      "|  -4.54818766125421|\n",
      "|-3.6548982915489905|\n",
      "| -4.467662111705454|\n",
      "|-3.6498121002774733|\n",
      "|  -4.13878862583068|\n",
      "| -3.521314262564103|\n",
      "| -6.045377130538534|\n",
      "| -5.788989024951549|\n",
      "| -6.261605945319069|\n",
      "| -4.437153214718968|\n",
      "| -5.243326251885563|\n",
      "| -4.086259295140323|\n",
      "| -4.682649077263664|\n",
      "| -4.872696719793019|\n",
      "|-2.8496170326188874|\n",
      "| -4.393711343103702|\n",
      "| -5.026771649986441|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df.n - 5).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### iv. Multiply the `n` column by 2. View the results along with the original numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|                   n|             (n * 2)|\n",
      "+--------------------+--------------------+\n",
      "|  -0.712390662050588|  -1.424781324101176|\n",
      "|   0.753766378659703|   1.507532757319406|\n",
      "|-0.04450307833805...|-0.08900615667610691|\n",
      "| 0.45181233874578974|  0.9036246774915795|\n",
      "|  1.3451017084510097|  2.6902034169020195|\n",
      "|  0.5323378882945463|  1.0646757765890926|\n",
      "|  1.3501878997225267|  2.7003757994450535|\n",
      "|  0.8612113741693206|  1.7224227483386412|\n",
      "|  1.4786857374358966|   2.957371474871793|\n",
      "| -1.0453771305385342| -2.0907542610770684|\n",
      "| -0.7889890249515489| -1.5779780499030978|\n",
      "|  -1.261605945319069|  -2.523211890638138|\n",
      "|  0.5628467852810314|  1.1256935705620628|\n",
      "|-0.24332625188556253|-0.48665250377112507|\n",
      "|  0.9137407048596775|   1.827481409719355|\n",
      "| 0.31735092273633597|  0.6347018454726719|\n",
      "| 0.12730328020698067| 0.25460656041396135|\n",
      "|  2.1503829673811126|   4.300765934762225|\n",
      "|  0.6062886568962988|  1.2125773137925977|\n",
      "|-0.02677164998644...|-0.05354329997288145|\n",
      "+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('n', df.n * 2).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### v. Add a new column named `n2` that is the `n` value multiplied by -1. Show the first 4 rows of your dataframe. You should see the original `n` value as well as `n2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-----+--------------------+\n",
      "|                   n|group|abool|                  n2|\n",
      "+--------------------+-----+-----+--------------------+\n",
      "|  -0.712390662050588|    z|false|   0.712390662050588|\n",
      "|   0.753766378659703|    x|false|  -0.753766378659703|\n",
      "|-0.04450307833805...|    z|false|0.044503078338053455|\n",
      "| 0.45181233874578974|    y|false|-0.45181233874578974|\n",
      "+--------------------+-----+-----+--------------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#needs reassigning to modify df\n",
    "n2 = (df.n * - 1).alias('n2')\n",
    "\n",
    "df = df.select('*', n2)\n",
    "df.show(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### vi. Add a new column named `n3` that is the n value squared. Show the first 5 rows of your dataframe. You should see both `n`, `n2`, and `n3`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-----+--------------------+--------------------+\n",
      "|                   n|group|abool|                  n2|                  n3|\n",
      "+--------------------+-----+-----+--------------------+--------------------+\n",
      "|  -0.712390662050588|    z|false|   0.712390662050588|   0.507500455376875|\n",
      "|   0.753766378659703|    x|false|  -0.753766378659703|  0.5681637535977627|\n",
      "|-0.04450307833805...|    z|false|0.044503078338053455|0.001980523981562...|\n",
      "| 0.45181233874578974|    y|false|-0.45181233874578974| 0.20413438944294027|\n",
      "|  1.3451017084510097|    z|false| -1.3451017084510097|  1.8092986060778251|\n",
      "+--------------------+-----+-----+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n3 = (df.n ** 2).alias('n3')\n",
    "\n",
    "df = df.select('*', n3)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### vii. What happens when you run the code below?\n",
    "\n",
    "`df.group + df.abool`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'(group + abool)'>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#add string to a bool\n",
    "#spark adds them together, but what if we use .select (cell below)\n",
    "df.group + df.abool\n",
    "\n",
    "#this doesn't produce an error, cause spark hasn't done any evaluating yet (w/ .select or .show)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### viii. What happens when you run the code below? What is the difference between this and the previous code sample?\n",
    "\n",
    "`df.select(df.group + df.abool)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.select(df.group + df.abool)\n",
    "\n",
    "#error message:\n",
    "#AnalysisException: cannot resolve '(CAST(`group` AS DOUBLE) + `abool`)' due to data type mismatch: differing types in '(CAST(`group` AS DOUBLE) + `abool`)' (double and boolean).;\n",
    "#'Project [(cast(group#431 as double) + abool#432) AS (group + abool)#843]\n",
    "#+- Project [n#430, group#431, abool#432, n2#794, POWER(n#430, cast(2 as double)) AS n3#816]\n",
    "#   +- Project [n#430, group#431, abool#432, (n#430 * cast(-1 as double)) AS n2#794]\n",
    "#      +- LogicalRDD [n#430, group#431, abool#432], false"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ix. Try adding various other columns together. What are the results of combining the different data types?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-----+--------------------+--------------------+--------------------+\n",
      "|                   n|group|abool|                  n2|                  n3|                  n4|\n",
      "+--------------------+-----+-----+--------------------+--------------------+--------------------+\n",
      "|  -0.712390662050588|    z|false|   0.712390662050588|   0.507500455376875|    1.01500091075375|\n",
      "|   0.753766378659703|    x|false|  -0.753766378659703|  0.5681637535977627|  1.1363275071955254|\n",
      "|-0.04450307833805...|    z|false|0.044503078338053455|0.001980523981562...|0.003961047963125845|\n",
      "| 0.45181233874578974|    y|false|-0.45181233874578974| 0.20413438944294027| 0.40826877888588053|\n",
      "|  1.3451017084510097|    z|false| -1.3451017084510097|  1.8092986060778251|  3.6185972121556502|\n",
      "+--------------------+-----+-----+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#adding all n's together\n",
    "n4 = (df.n * 2 + df.n2 *2 + df.n3 *2).alias('n4')\n",
    "\n",
    "df = df.select(('*'), n4).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Type casting\n",
    "\n",
    "#### i. Use the starter code above to re-create a spark dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-----+\n",
      "|                   n|group|abool|\n",
      "+--------------------+-----+-----+\n",
      "|  -0.712390662050588|    z|false|\n",
      "|   0.753766378659703|    x|false|\n",
      "|-0.04450307833805...|    z|false|\n",
      "| 0.45181233874578974|    y|false|\n",
      "|  1.3451017084510097|    z|false|\n",
      "+--------------------+-----+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(13)\n",
    "\n",
    "pandas_dataframe = pd.DataFrame({\n",
    "    \"n\": np.random.randn(20),\n",
    "    \"group\": np.random.choice(list(\"xyz\"), 20),\n",
    "    \"abool\": np.random.choice([True, False], 20),\n",
    "})\n",
    "\n",
    "df = spark.createDataFrame(pandas_dataframe)\n",
    "\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ii. Use `.printSchema` to view the datatypes in your dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- n: double (nullable = true)\n",
      " |-- group: string (nullable = true)\n",
      " |-- abool: boolean (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### iii. Use `.dtypes` to view the datatypes in your dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('n', 'double'), ('group', 'string'), ('abool', 'boolean')]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### iv. What is the difference between the two code samples below?\n",
    "\n",
    "`df.abool.cast('int')`\n",
    "\n",
    "\n",
    "`df.select(df.abool.cast('int')).show()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'CAST(abool AS INT)'>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.abool.cast('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|abool|\n",
      "+-----+\n",
      "|    0|\n",
      "|    0|\n",
      "|    0|\n",
      "|    0|\n",
      "|    0|\n",
      "|    0|\n",
      "|    0|\n",
      "|    0|\n",
      "|    1|\n",
      "|    1|\n",
      "|    0|\n",
      "|    0|\n",
      "|    1|\n",
      "|    1|\n",
      "|    0|\n",
      "|    0|\n",
      "|    0|\n",
      "|    1|\n",
      "|    0|\n",
      "|    1|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df.abool.cast('int')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### v. Use `.select` and `.cast` to convert the `abool` column to an integer type. View the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|abool|abool|\n",
      "+-----+-----+\n",
      "|false|    0|\n",
      "|false|    0|\n",
      "|false|    0|\n",
      "|false|    0|\n",
      "|false|    0|\n",
      "|false|    0|\n",
      "|false|    0|\n",
      "|false|    0|\n",
      "| true|    1|\n",
      "| true|    1|\n",
      "|false|    0|\n",
      "|false|    0|\n",
      "| true|    1|\n",
      "| true|    1|\n",
      "|false|    0|\n",
      "|false|    0|\n",
      "|false|    0|\n",
      "| true|    1|\n",
      "|false|    0|\n",
      "| true|    1|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('abool', df.abool.cast('int')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### vi. Convert the `group` column to a integer data type and view the results. What happens?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|group|group|\n",
      "+-----+-----+\n",
      "|    z| null|\n",
      "|    x| null|\n",
      "|    z| null|\n",
      "|    y| null|\n",
      "|    z| null|\n",
      "|    y| null|\n",
      "|    z| null|\n",
      "|    x| null|\n",
      "|    z| null|\n",
      "|    y| null|\n",
      "|    x| null|\n",
      "|    y| null|\n",
      "|    y| null|\n",
      "|    y| null|\n",
      "|    y| null|\n",
      "|    x| null|\n",
      "|    z| null|\n",
      "|    y| null|\n",
      "|    x| null|\n",
      "|    x| null|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('group', df.group.cast('int')).show()\n",
    "#null b/c group is a string obj and it does not exist as int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### vii. Convert the `n` column to a integer data type and view the results. What happens?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---+\n",
      "|                   n|  n|\n",
      "+--------------------+---+\n",
      "|  -0.712390662050588|  0|\n",
      "|   0.753766378659703|  0|\n",
      "|-0.04450307833805...|  0|\n",
      "| 0.45181233874578974|  0|\n",
      "|  1.3451017084510097|  1|\n",
      "|  0.5323378882945463|  0|\n",
      "|  1.3501878997225267|  1|\n",
      "|  0.8612113741693206|  0|\n",
      "|  1.4786857374358966|  1|\n",
      "| -1.0453771305385342| -1|\n",
      "| -0.7889890249515489|  0|\n",
      "|  -1.261605945319069| -1|\n",
      "|  0.5628467852810314|  0|\n",
      "|-0.24332625188556253|  0|\n",
      "|  0.9137407048596775|  0|\n",
      "| 0.31735092273633597|  0|\n",
      "| 0.12730328020698067|  0|\n",
      "|  2.1503829673811126|  2|\n",
      "|  0.6062886568962988|  0|\n",
      "|-0.02677164998644...|  0|\n",
      "+--------------------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('n', df.n.cast('int')).show()\n",
    "#gets rid of decimals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### viii. Convert the `abool` column to a string data type and view the results. What happens?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|abool|abool|\n",
      "+-----+-----+\n",
      "|false|false|\n",
      "|false|false|\n",
      "|false|false|\n",
      "|false|false|\n",
      "|false|false|\n",
      "|false|false|\n",
      "|false|false|\n",
      "|false|false|\n",
      "| true| true|\n",
      "| true| true|\n",
      "|false|false|\n",
      "|false|false|\n",
      "| true| true|\n",
      "| true| true|\n",
      "|false|false|\n",
      "|false|false|\n",
      "|false|false|\n",
      "| true| true|\n",
      "|false|false|\n",
      "| true| true|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('abool', df.abool.cast('string')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('abool', 'boolean'), ('abool', 'string')]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#above reads the same but dtypes are different\n",
    "df.select('abool', df.abool.cast('string')).dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Built-in Functions\n",
    "\n",
    "#### i. Use the starter code above to re-create a spark dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-----+\n",
      "|                   n|group|abool|\n",
      "+--------------------+-----+-----+\n",
      "|  -0.712390662050588|    z|false|\n",
      "|   0.753766378659703|    x|false|\n",
      "|-0.04450307833805...|    z|false|\n",
      "| 0.45181233874578974|    y|false|\n",
      "|  1.3451017084510097|    z|false|\n",
      "+--------------------+-----+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(13)\n",
    "\n",
    "pandas_dataframe = pd.DataFrame({\n",
    "    \"n\": np.random.randn(20),\n",
    "    \"group\": np.random.choice(list(\"xyz\"), 20),\n",
    "    \"abool\": np.random.choice([True, False], 20),\n",
    "})\n",
    "\n",
    "df = spark.createDataFrame(pandas_dataframe)\n",
    "\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ii. Import the necessary functions from `pyspark.sql.functions`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import min, max, mean, concat, lit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### iii. Find the highest `n` value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|            max(n)|\n",
      "+------------------+\n",
      "|2.1503829673811126|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(max('n')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### iv. Find the lowest `n` value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|            min(n)|\n",
      "+------------------+\n",
      "|-1.261605945319069|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(min('n')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### v. Find the average `n` value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|             avg(n)|\n",
      "+-------------------+\n",
      "|0.36640264498852165|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(mean('n')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### vi. Use `concat` to change the `group` column to say, e.g. \"Group: x\" or \"Group: y\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+\n",
      "|group|group_name|\n",
      "+-----+----------+\n",
      "|    z|  Group: z|\n",
      "|    x|  Group: x|\n",
      "|    z|  Group: z|\n",
      "|    y|  Group: y|\n",
      "|    z|  Group: z|\n",
      "|    y|  Group: y|\n",
      "|    z|  Group: z|\n",
      "|    x|  Group: x|\n",
      "|    z|  Group: z|\n",
      "|    y|  Group: y|\n",
      "|    x|  Group: x|\n",
      "|    y|  Group: y|\n",
      "|    y|  Group: y|\n",
      "|    y|  Group: y|\n",
      "|    y|  Group: y|\n",
      "|    x|  Group: x|\n",
      "|    z|  Group: z|\n",
      "|    y|  Group: y|\n",
      "|    x|  Group: x|\n",
      "|    x|  Group: x|\n",
      "+-----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('group', concat(lit('Group: '), 'group').alias(\"group_name\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### vii. Use `concat` to combine the `n` and `group` columns to produce results that look like this: \"x: -1.432\" or \"z: 2.352\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|       combined_cols|\n",
      "+--------------------+\n",
      "|z: -0.71239066205...|\n",
      "|x: 0.753766378659703|\n",
      "|z: -0.04450307833...|\n",
      "|y: 0.451812338745...|\n",
      "|z: 1.345101708451...|\n",
      "|y: 0.532337888294...|\n",
      "|z: 1.350187899722...|\n",
      "|x: 0.861211374169...|\n",
      "|z: 1.478685737435...|\n",
      "|y: -1.04537713053...|\n",
      "|x: -0.78898902495...|\n",
      "|y: -1.26160594531...|\n",
      "|y: 0.562846785281...|\n",
      "|y: -0.24332625188...|\n",
      "|y: 0.913740704859...|\n",
      "|x: 0.317350922736...|\n",
      "|z: 0.127303280206...|\n",
      "|y: 2.150382967381...|\n",
      "|x: 0.606288656896...|\n",
      "|x: -0.02677164998...|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(concat('group', lit(': '), 'n').alias('combined_cols')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. When / Otherwise\n",
    "\n",
    "#### i. Use the starter code above to re-create a spark dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-----+\n",
      "|                   n|group|abool|\n",
      "+--------------------+-----+-----+\n",
      "|  -0.712390662050588|    z|false|\n",
      "|   0.753766378659703|    x|false|\n",
      "|-0.04450307833805...|    z|false|\n",
      "| 0.45181233874578974|    y|false|\n",
      "|  1.3451017084510097|    z|false|\n",
      "+--------------------+-----+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(13)\n",
    "\n",
    "pandas_dataframe = pd.DataFrame({\n",
    "    \"n\": np.random.randn(20),\n",
    "    \"group\": np.random.choice(list(\"xyz\"), 20),\n",
    "    \"abool\": np.random.choice([True, False], 20),\n",
    "})\n",
    "\n",
    "df = spark.createDataFrame(pandas_dataframe)\n",
    "\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ii. Use `when` and `.otherwise` to create a column that contains the text \"It is true\" when `abool` is true and \"It is false\"\" when `abool` is false."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------+\n",
      "|abool|What is it?|\n",
      "+-----+-----------+\n",
      "|false|It is false|\n",
      "|false|It is false|\n",
      "|false|It is false|\n",
      "|false|It is false|\n",
      "|false|It is false|\n",
      "|false|It is false|\n",
      "|false|It is false|\n",
      "|false|It is false|\n",
      "| true| It is true|\n",
      "| true| It is true|\n",
      "|false|It is false|\n",
      "|false|It is false|\n",
      "| true| It is true|\n",
      "| true| It is true|\n",
      "|false|It is false|\n",
      "|false|It is false|\n",
      "|false|It is false|\n",
      "| true| It is true|\n",
      "|false|It is false|\n",
      "| true| It is true|\n",
      "+-----+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df.abool, \n",
    "          when(df.abool == 'true', 'It is true')\n",
    "          .otherwise('It is false')\n",
    "          .alias('What is it?'))\n",
    ".show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------+\n",
      "|abool|    message|\n",
      "+-----+-----------+\n",
      "|false|It is false|\n",
      "|false|It is false|\n",
      "|false|It is false|\n",
      "|false|It is false|\n",
      "|false|It is false|\n",
      "|false|It is false|\n",
      "|false|It is false|\n",
      "|false|It is false|\n",
      "| true| It is true|\n",
      "| true| It is true|\n",
      "|false|It is false|\n",
      "|false|It is false|\n",
      "| true| It is true|\n",
      "| true| It is true|\n",
      "|false|It is false|\n",
      "|false|It is false|\n",
      "|false|It is false|\n",
      "| true| It is true|\n",
      "|false|It is false|\n",
      "| true| It is true|\n",
      "+-----+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#alternate\n",
    "df.select(\n",
    "    'abool',\n",
    "    when(df.abool, 'It is true').otherwise('It is false').alias('message')\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### iii. Create a column that contains 0 if `n` is less than 0, otherwise, the original `n` value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------------------------------+\n",
      "|                   n|CASE WHEN (n < 0) THEN 0 ELSE n END|\n",
      "+--------------------+-----------------------------------+\n",
      "|  -0.712390662050588|                                0.0|\n",
      "|   0.753766378659703|                  0.753766378659703|\n",
      "|-0.04450307833805...|                                0.0|\n",
      "| 0.45181233874578974|                0.45181233874578974|\n",
      "|  1.3451017084510097|                 1.3451017084510097|\n",
      "|  0.5323378882945463|                 0.5323378882945463|\n",
      "|  1.3501878997225267|                 1.3501878997225267|\n",
      "|  0.8612113741693206|                 0.8612113741693206|\n",
      "|  1.4786857374358966|                 1.4786857374358966|\n",
      "| -1.0453771305385342|                                0.0|\n",
      "| -0.7889890249515489|                                0.0|\n",
      "|  -1.261605945319069|                                0.0|\n",
      "|  0.5628467852810314|                 0.5628467852810314|\n",
      "|-0.24332625188556253|                                0.0|\n",
      "|  0.9137407048596775|                 0.9137407048596775|\n",
      "| 0.31735092273633597|                0.31735092273633597|\n",
      "| 0.12730328020698067|                0.12730328020698067|\n",
      "|  2.1503829673811126|                 2.1503829673811126|\n",
      "|  0.6062886568962988|                 0.6062886568962988|\n",
      "|-0.02677164998644...|                                0.0|\n",
      "+--------------------+-----------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('n', when(df.n < 0, 0).otherwise(df.n)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Filter / Where\n",
    "\n",
    "#### i. Use the starter code above to re-create a spark dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-----+\n",
      "|                   n|group|abool|\n",
      "+--------------------+-----+-----+\n",
      "|  -0.712390662050588|    z|false|\n",
      "|   0.753766378659703|    x|false|\n",
      "|-0.04450307833805...|    z|false|\n",
      "| 0.45181233874578974|    y|false|\n",
      "|  1.3451017084510097|    z|false|\n",
      "+--------------------+-----+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(13)\n",
    "\n",
    "pandas_dataframe = pd.DataFrame({\n",
    "    \"n\": np.random.randn(20),\n",
    "    \"group\": np.random.choice(list(\"xyz\"), 20),\n",
    "    \"abool\": np.random.choice([True, False], 20),\n",
    "})\n",
    "\n",
    "df = spark.createDataFrame(pandas_dataframe)\n",
    "\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ii. Use `.filter` or `.where` to select just the rows where the group is `y` and view the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-----+\n",
      "|                   n|group|abool|\n",
      "+--------------------+-----+-----+\n",
      "| 0.45181233874578974|    y|false|\n",
      "|  0.5323378882945463|    y|false|\n",
      "| -1.0453771305385342|    y| true|\n",
      "|  -1.261605945319069|    y|false|\n",
      "|  0.5628467852810314|    y| true|\n",
      "|-0.24332625188556253|    y| true|\n",
      "|  0.9137407048596775|    y|false|\n",
      "|  2.1503829673811126|    y| true|\n",
      "+--------------------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df.group == 'y').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### iii. Select just the columns where the `abool` column is false and view the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-----+\n",
      "|                   n|group|abool|\n",
      "+--------------------+-----+-----+\n",
      "|  -0.712390662050588|    z|false|\n",
      "|   0.753766378659703|    x|false|\n",
      "|-0.04450307833805...|    z|false|\n",
      "| 0.45181233874578974|    y|false|\n",
      "|  1.3451017084510097|    z|false|\n",
      "|  0.5323378882945463|    y|false|\n",
      "|  1.3501878997225267|    z|false|\n",
      "|  0.8612113741693206|    x|false|\n",
      "| -0.7889890249515489|    x|false|\n",
      "|  -1.261605945319069|    y|false|\n",
      "|  0.9137407048596775|    y|false|\n",
      "| 0.31735092273633597|    x|false|\n",
      "| 0.12730328020698067|    z|false|\n",
      "|  0.6062886568962988|    x|false|\n",
      "+--------------------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.where(df.abool == 'false').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-----+\n",
      "|                   n|group|abool|\n",
      "+--------------------+-----+-----+\n",
      "|  -0.712390662050588|    z|false|\n",
      "|   0.753766378659703|    x|false|\n",
      "|-0.04450307833805...|    z|false|\n",
      "| 0.45181233874578974|    y|false|\n",
      "|  1.3451017084510097|    z|false|\n",
      "|  0.5323378882945463|    y|false|\n",
      "|  1.3501878997225267|    z|false|\n",
      "|  0.8612113741693206|    x|false|\n",
      "| -0.7889890249515489|    x|false|\n",
      "|  -1.261605945319069|    y|false|\n",
      "|  0.9137407048596775|    y|false|\n",
      "| 0.31735092273633597|    x|false|\n",
      "| 0.12730328020698067|    z|false|\n",
      "|  0.6062886568962988|    x|false|\n",
      "+--------------------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#alternate\n",
    "df.filter(~ df.abool).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### iv. Find the columns where the `group` column is *not* `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-----+\n",
      "|                   n|group|abool|\n",
      "+--------------------+-----+-----+\n",
      "|  -0.712390662050588|    z|false|\n",
      "|   0.753766378659703|    x|false|\n",
      "|-0.04450307833805...|    z|false|\n",
      "|  1.3451017084510097|    z|false|\n",
      "|  1.3501878997225267|    z|false|\n",
      "|  0.8612113741693206|    x|false|\n",
      "|  1.4786857374358966|    z| true|\n",
      "| -0.7889890249515489|    x|false|\n",
      "| 0.31735092273633597|    x|false|\n",
      "| 0.12730328020698067|    z|false|\n",
      "|  0.6062886568962988|    x|false|\n",
      "|-0.02677164998644...|    x| true|\n",
      "+--------------------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.where(df.group != 'y').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### v. Find the columns where `n` is positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----+-----+\n",
      "|                  n|group|abool|\n",
      "+-------------------+-----+-----+\n",
      "|  0.753766378659703|    x|false|\n",
      "|0.45181233874578974|    y|false|\n",
      "| 1.3451017084510097|    z|false|\n",
      "| 0.5323378882945463|    y|false|\n",
      "| 1.3501878997225267|    z|false|\n",
      "| 0.8612113741693206|    x|false|\n",
      "| 1.4786857374358966|    z| true|\n",
      "| 0.5628467852810314|    y| true|\n",
      "| 0.9137407048596775|    y|false|\n",
      "|0.31735092273633597|    x|false|\n",
      "|0.12730328020698067|    z|false|\n",
      "| 2.1503829673811126|    y| true|\n",
      "| 0.6062886568962988|    x|false|\n",
      "+-------------------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.where(df.n > 0).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### vi. Find the columns where `abool` is true and the `group` column is `z`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----+-----+\n",
      "|                 n|group|abool|\n",
      "+------------------+-----+-----+\n",
      "|1.4786857374358966|    z| true|\n",
      "+------------------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.where(df.abool == 'true').where(df.group == 'z').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----+-----+\n",
      "|                 n|group|abool|\n",
      "+------------------+-----+-----+\n",
      "|1.4786857374358966|    z| true|\n",
      "+------------------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#alternate\n",
    "df.filter(df.abool).filter(df.group == 'z').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### vii. Find the columns where `abool` is true or the `group` column is `z`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-----+\n",
      "|                   n|group|abool|\n",
      "+--------------------+-----+-----+\n",
      "|  -0.712390662050588|    z|false|\n",
      "|-0.04450307833805...|    z|false|\n",
      "|  1.3451017084510097|    z|false|\n",
      "|  1.3501878997225267|    z|false|\n",
      "|  1.4786857374358966|    z| true|\n",
      "| -1.0453771305385342|    y| true|\n",
      "|  0.5628467852810314|    y| true|\n",
      "|-0.24332625188556253|    y| true|\n",
      "| 0.12730328020698067|    z|false|\n",
      "|  2.1503829673811126|    y| true|\n",
      "|-0.02677164998644...|    x| true|\n",
      "+--------------------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.where(df.abool | (df.group == 'z')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### viii. Find the columns where `abool` is false and `n` is less than 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-----+\n",
      "|                   n|group|abool|\n",
      "+--------------------+-----+-----+\n",
      "|  -0.712390662050588|    z|false|\n",
      "|   0.753766378659703|    x|false|\n",
      "|-0.04450307833805...|    z|false|\n",
      "| 0.45181233874578974|    y|false|\n",
      "|  0.5323378882945463|    y|false|\n",
      "|  0.8612113741693206|    x|false|\n",
      "| -0.7889890249515489|    x|false|\n",
      "|  -1.261605945319069|    y|false|\n",
      "|  0.9137407048596775|    y|false|\n",
      "| 0.31735092273633597|    x|false|\n",
      "| 0.12730328020698067|    z|false|\n",
      "|  0.6062886568962988|    x|false|\n",
      "+--------------------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.where(df.abool == 'false').where(df.n < 1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-----+\n",
      "|                   n|group|abool|\n",
      "+--------------------+-----+-----+\n",
      "|  -0.712390662050588|    z|false|\n",
      "|   0.753766378659703|    x|false|\n",
      "|-0.04450307833805...|    z|false|\n",
      "| 0.45181233874578974|    y|false|\n",
      "|  0.5323378882945463|    y|false|\n",
      "|  0.8612113741693206|    x|false|\n",
      "| -0.7889890249515489|    x|false|\n",
      "|  -1.261605945319069|    y|false|\n",
      "|  0.9137407048596775|    y|false|\n",
      "| 0.31735092273633597|    x|false|\n",
      "| 0.12730328020698067|    z|false|\n",
      "|  0.6062886568962988|    x|false|\n",
      "+--------------------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#alternate\n",
    "df.filter(~ df.abool).filter(df.n < 1).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ix. Find the columns where `abool` is false or `n` is less than 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-----+\n",
      "|                   n|group|abool|\n",
      "+--------------------+-----+-----+\n",
      "|  -0.712390662050588|    z|false|\n",
      "|   0.753766378659703|    x|false|\n",
      "|-0.04450307833805...|    z|false|\n",
      "| 0.45181233874578974|    y|false|\n",
      "|  1.3451017084510097|    z|false|\n",
      "|  0.5323378882945463|    y|false|\n",
      "|  1.3501878997225267|    z|false|\n",
      "|  0.8612113741693206|    x|false|\n",
      "| -1.0453771305385342|    y| true|\n",
      "| -0.7889890249515489|    x|false|\n",
      "|  -1.261605945319069|    y|false|\n",
      "|  0.5628467852810314|    y| true|\n",
      "|-0.24332625188556253|    y| true|\n",
      "|  0.9137407048596775|    y|false|\n",
      "| 0.31735092273633597|    x|false|\n",
      "| 0.12730328020698067|    z|false|\n",
      "|  0.6062886568962988|    x|false|\n",
      "|-0.02677164998644...|    x| true|\n",
      "+--------------------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(~ df.abool | (df.n < 1)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Sorting\n",
    "\n",
    "#### i. Use the starter code above to re-create a spark dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-----+\n",
      "|                   n|group|abool|\n",
      "+--------------------+-----+-----+\n",
      "|  -0.712390662050588|    z|false|\n",
      "|   0.753766378659703|    x|false|\n",
      "|-0.04450307833805...|    z|false|\n",
      "| 0.45181233874578974|    y|false|\n",
      "|  1.3451017084510097|    z|false|\n",
      "+--------------------+-----+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(13)\n",
    "\n",
    "pandas_dataframe = pd.DataFrame({\n",
    "    \"n\": np.random.randn(20),\n",
    "    \"group\": np.random.choice(list(\"xyz\"), 20),\n",
    "    \"abool\": np.random.choice([True, False], 20),\n",
    "})\n",
    "\n",
    "df = spark.createDataFrame(pandas_dataframe)\n",
    "\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ii. Sort by the `n` value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-----+\n",
      "|                   n|group|abool|\n",
      "+--------------------+-----+-----+\n",
      "|  -1.261605945319069|    y|false|\n",
      "| -1.0453771305385342|    y| true|\n",
      "| -0.7889890249515489|    x|false|\n",
      "|  -0.712390662050588|    z|false|\n",
      "|-0.24332625188556253|    y| true|\n",
      "|-0.04450307833805...|    z|false|\n",
      "|-0.02677164998644...|    x| true|\n",
      "| 0.12730328020698067|    z|false|\n",
      "| 0.31735092273633597|    x|false|\n",
      "| 0.45181233874578974|    y|false|\n",
      "|  0.5323378882945463|    y|false|\n",
      "|  0.5628467852810314|    y| true|\n",
      "|  0.6062886568962988|    x|false|\n",
      "|   0.753766378659703|    x|false|\n",
      "|  0.8612113741693206|    x|false|\n",
      "|  0.9137407048596775|    y|false|\n",
      "|  1.3451017084510097|    z|false|\n",
      "|  1.3501878997225267|    z|false|\n",
      "|  1.4786857374358966|    z| true|\n",
      "|  2.1503829673811126|    y| true|\n",
      "+--------------------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.sort('n').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### iii. Sort by the `group` value, both ascending and descending."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-----+\n",
      "|                   n|group|abool|\n",
      "+--------------------+-----+-----+\n",
      "|-0.02677164998644...|    x| true|\n",
      "|  0.6062886568962988|    x|false|\n",
      "| 0.31735092273633597|    x|false|\n",
      "|  0.8612113741693206|    x|false|\n",
      "| -0.7889890249515489|    x|false|\n",
      "|   0.753766378659703|    x|false|\n",
      "| -1.0453771305385342|    y| true|\n",
      "|  -1.261605945319069|    y|false|\n",
      "|-0.24332625188556253|    y| true|\n",
      "| 0.45181233874578974|    y|false|\n",
      "|  0.5323378882945463|    y|false|\n",
      "|  2.1503829673811126|    y| true|\n",
      "|  0.5628467852810314|    y| true|\n",
      "|  0.9137407048596775|    y|false|\n",
      "|  1.3501878997225267|    z|false|\n",
      "|  1.4786857374358966|    z| true|\n",
      "|  -0.712390662050588|    z|false|\n",
      "| 0.12730328020698067|    z|false|\n",
      "|-0.04450307833805...|    z|false|\n",
      "|  1.3451017084510097|    z|false|\n",
      "+--------------------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.sort('group').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-----+\n",
      "|                   n|group|abool|\n",
      "+--------------------+-----+-----+\n",
      "|  1.3451017084510097|    z|false|\n",
      "|  1.3501878997225267|    z|false|\n",
      "|-0.04450307833805...|    z|false|\n",
      "|  1.4786857374358966|    z| true|\n",
      "| 0.12730328020698067|    z|false|\n",
      "|  -0.712390662050588|    z|false|\n",
      "|  -1.261605945319069|    y|false|\n",
      "|  0.5323378882945463|    y|false|\n",
      "|  2.1503829673811126|    y| true|\n",
      "| 0.45181233874578974|    y|false|\n",
      "| -1.0453771305385342|    y| true|\n",
      "|-0.24332625188556253|    y| true|\n",
      "|  0.9137407048596775|    y|false|\n",
      "|  0.5628467852810314|    y| true|\n",
      "|   0.753766378659703|    x|false|\n",
      "| -0.7889890249515489|    x|false|\n",
      "|  0.8612113741693206|    x|false|\n",
      "| 0.31735092273633597|    x|false|\n",
      "|-0.02677164998644...|    x| true|\n",
      "|  0.6062886568962988|    x|false|\n",
      "+--------------------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.sort(df.group.desc()).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### iv. Sort by the group value first, then, within each group, sort by `n` value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-----+\n",
      "|                   n|group|abool|\n",
      "+--------------------+-----+-----+\n",
      "| -0.7889890249515489|    x|false|\n",
      "|-0.02677164998644...|    x| true|\n",
      "| 0.31735092273633597|    x|false|\n",
      "|  0.6062886568962988|    x|false|\n",
      "|   0.753766378659703|    x|false|\n",
      "|  0.8612113741693206|    x|false|\n",
      "|  -1.261605945319069|    y|false|\n",
      "| -1.0453771305385342|    y| true|\n",
      "|-0.24332625188556253|    y| true|\n",
      "| 0.45181233874578974|    y|false|\n",
      "|  0.5323378882945463|    y|false|\n",
      "|  0.5628467852810314|    y| true|\n",
      "|  0.9137407048596775|    y|false|\n",
      "|  2.1503829673811126|    y| true|\n",
      "|  -0.712390662050588|    z|false|\n",
      "|-0.04450307833805...|    z|false|\n",
      "| 0.12730328020698067|    z|false|\n",
      "|  1.3451017084510097|    z|false|\n",
      "|  1.3501878997225267|    z|false|\n",
      "|  1.4786857374358966|    z| true|\n",
      "+--------------------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.sort(df.group, df.n).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### v. Sort by `abool`, `group`, and `n`. Does it matter in what order you specify the columns when sorting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-----+\n",
      "|                   n|group|abool|\n",
      "+--------------------+-----+-----+\n",
      "| -0.7889890249515489|    x|false|\n",
      "| 0.31735092273633597|    x|false|\n",
      "|  0.6062886568962988|    x|false|\n",
      "|   0.753766378659703|    x|false|\n",
      "|  0.8612113741693206|    x|false|\n",
      "|  -1.261605945319069|    y|false|\n",
      "| 0.45181233874578974|    y|false|\n",
      "|  0.5323378882945463|    y|false|\n",
      "|  0.9137407048596775|    y|false|\n",
      "|  -0.712390662050588|    z|false|\n",
      "|-0.04450307833805...|    z|false|\n",
      "| 0.12730328020698067|    z|false|\n",
      "|  1.3451017084510097|    z|false|\n",
      "|  1.3501878997225267|    z|false|\n",
      "|-0.02677164998644...|    x| true|\n",
      "| -1.0453771305385342|    y| true|\n",
      "|-0.24332625188556253|    y| true|\n",
      "|  0.5628467852810314|    y| true|\n",
      "|  2.1503829673811126|    y| true|\n",
      "|  1.4786857374358966|    z| true|\n",
      "+--------------------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.sort(df.abool, df.group, df.n).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Spark SQL\n",
    "\n",
    "#### i. Use the starter code above to re-create a spark dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ii. Turn your dataframe into a table that can be queried with spark SQL. Name the table `my_df`. Answer the rest of the questions in this section with a spark sql query (`spark.sql`) against `my_df`. After each step, view the first 7 records from the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### iii. Write a query that shows all of the columns from your dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### iv. Write a query that shows just the `n` and `abool` columns from the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### v. Write a query that shows just the `n` and `group` columns. Rename the `group` column to `g`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### vi. Write a query that selects `n`, and creates two new columns: `n2`, the original `n` values halved, and `n3`: the original `n` values minus 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### vii. What happens if you make a SQL syntax error in your query?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Aggregating\n",
    "\n",
    "#### i. What is the average `n` value for each group in the `group` column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ii. What is the maximum `n` value for each group in the `group` column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### iii. What is the minimum `n` value by `abool`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### iv. What is the average `n` value for each unique combination of the `group` and `abool` column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bonus: Revisit the exercises for the [pandas dataframes](https://ds.codeup.com/python/dataframes/) lesson and the [advanced dataframes lesson](https://ds.codeup.com/python/advanced-dataframes/). Complete the exercises, but convert the pandas dataframes to spark dataframes first in order to practice using the spark api."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
